{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0ff73030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from implicit import bpr\n",
    "from implicit.cpu.lmf import LogisticMatrixFactorization\n",
    "from implicit.cpu.als import AlternatingLeastSquares\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from lightfm import LightFM\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "import lightfm\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c391c",
   "metadata": {},
   "source": [
    "# Would Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43610be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    f = open(path)\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        yield u,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14eff64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = []\n",
    "for l in readJSON(\"train.json\"):\n",
    "    rawData.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc3b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rawData)\n",
    "train = rawData[:165000]\n",
    "valid = rawData[165000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8c509a",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerGame = defaultdict(set)\n",
    "gamesPerUser = defaultdict(set)\n",
    "for user,game in rawData:\n",
    "    usersPerGame[game].add(user)\n",
    "    gamesPerUser[user].add(game)\n",
    "games = list(usersPerGame.keys())\n",
    "users = list(gamesPerUser.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c6b5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostPopularGames(data,threshold):\n",
    "    gameCount = defaultdict(int)\n",
    "    \n",
    "    for user,game in data:\n",
    "        gameCount[game] += 1\n",
    "    \n",
    "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "    \n",
    "    mostPopularGames= set()\n",
    "    notPopularGames = set()\n",
    "    count = 0\n",
    "    \n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        if count <= threshold:\n",
    "            mostPopularGames.add(i)\n",
    "        if count > threshold: \n",
    "            notPopularGames.add(i)#break\n",
    "    return mostPopularGames,notPopularGames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04feff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gameCount = defaultdict(int)\n",
    "for user,game in train:\n",
    "    gameCount[game] += 1\n",
    "    \n",
    "    \n",
    "mostPopular = [(gameCount[x], x) for x in gameCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "gamerank = {}\n",
    "gamePop = {}\n",
    "for i in range(len(mostPopular)):\n",
    "    gamerank[mostPopular[i][1]] = i+1\n",
    "    gamePop[mostPopular[i][1]] = (int(mostPopular[i][0])/mostPopular[0][0])\n",
    "#gamePop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d1bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "newValid = []\n",
    "falseSamples = defaultdict(list)\n",
    "for u,g in valid:\n",
    "    newValid.append([u,g,1])\n",
    "    res1 = random.sample([ele for ele in games if ele not in list(gamesPerUser[u])+falseSamples[u]],1)\n",
    "    falseSamples[u].extend(res1)\n",
    "    newValid.append([u,res1[0],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94218d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc08c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosineSet(s1, s2):\n",
    "    # Not a proper implementation, operates on sets so correct for interactions only\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = math.sqrt(len(s1)) * math.sqrt(len(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e70434",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerGameTrain = defaultdict(set)\n",
    "gamesPerUserTrain = defaultdict(set)\n",
    "for user,game in train:\n",
    "    usersPerGameTrain[game].add(user)\n",
    "    gamesPerUserTrain[user].add(game)\n",
    "gamesTrain = list(usersPerGameTrain.keys())\n",
    "usersTrain = list(gamesPerUserTrain.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17331d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sims = []\n",
    "for i in range(len(newValid)):\n",
    "    u = newValid[i][0]\n",
    "    g = newValid[i][1]\n",
    "    gamesByUser = gamesPerUserTrain[u]\n",
    "    users = usersPerGameTrain[g]\n",
    "    max_sim = 0\n",
    "    \n",
    "    for g_ in gamesByUser:\n",
    "        if (g_==g): continue\n",
    "        sim = Jaccard(users, usersPerGameTrain[g_])\n",
    "        max_sim = max(max_sim,sim)\n",
    "\n",
    "    max_sims.append(max_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0ae532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs,itemIDs = {},{}\n",
    "\n",
    "for u,i in train:\n",
    "    #u,i = d['user_id'],d['book_id']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "\n",
    "nUsers,nItems = len(userIDs),len(itemIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xui = scipy.sparse.lil_matrix((nUsers, nItems))\n",
    "for u,g in train:\n",
    "    Xui[userIDs[u],itemIDs[g]] = 1\n",
    "    \n",
    "Xui_csr = scipy.sparse.csr_matrix(Xui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ac90aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37bc3e19bcb4b76bb1491c8cea4ee91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = bpr.BayesianPersonalizedRanking(factors = 3)\n",
    "model2.fit(Xui_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07caeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_score = []\n",
    "for u,i,l in newValid:\n",
    "    print(u)\n",
    "    if(u not in userIDs):\n",
    "        bpr_score.append(0)\n",
    "        continue\n",
    "    uid = userIDs[u]\n",
    "    ids, scores = model2.recommend(uid, Xui_csr[uid],N=nItems)\n",
    "    #print(scores)\n",
    "    s = scores[list(ids).index(itemIDs[i])]\n",
    "    bpr_score.append(s)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "412805f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e562acbf7c614d97b193469c1309739a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model3 = LogisticMatrixFactorization(factors = 3)\n",
    "model3.fit(Xui_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmf_score = []\n",
    "for u,i,l in newValid:\n",
    "    print(u)\n",
    "    if(u not in userIDs):\n",
    "        lmf_score.append(0)\n",
    "        continue\n",
    "    uid = userIDs[u]\n",
    "    ids, scores = model3.recommend(uid, Xui_csr[uid],N=nItems)\n",
    "    s = scores[list(ids).index(itemIDs[i])]\n",
    "    lmf_score.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebc376df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg,npg = mostPopularGames(train,len(train)*0.75)\n",
    "features = []\n",
    "y = []\n",
    "for i in range(len(newValid)):\n",
    "    y.append(newValid[i][2])\n",
    "    \n",
    "    temp = [1]\n",
    "#     if newValid[i][1] in mpg:\n",
    "#         temp.append(1)\n",
    "#     else:\n",
    "#         temp.append(0)\n",
    "        \n",
    "    temp.append(max_sims[i])\n",
    "    #temp.append(gamerank[newValid[i][1]])\n",
    "    temp.append(gamePop[newValid[i][1]])\n",
    "    temp.append(bpr_score[i])\n",
    "    temp.append(lmf_score[i])\n",
    "    features.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea3946f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7384238423842384"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = linear_model.LogisticRegression(C=1,max_iter=500)\n",
    "model1 = GradientBoostingClassifier()\n",
    "#model1 = SGDClassifier()\n",
    "model1.fit(features,y)\n",
    "valid_pred = model1.predict(features)\n",
    "accuracy = sum(valid_pred==y)/len(y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f080e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Played.csv\", 'w')\n",
    "for l in open(\"pairs_Played.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    gamesByUser = gamesPerUserTrain[u]\n",
    "    users = usersPerGameTrain[g]\n",
    "    max_sim = 0\n",
    "\n",
    "    \n",
    "    for g_ in gamesByUser:\n",
    "        if (g_==g): continue\n",
    "        sim = Jaccard(users, usersPerGameTrain[g_])\n",
    "        max_sim = max(max_sim,sim)\n",
    "        \n",
    "    if(u not in userIDs):\n",
    "        bs=0#sum(bpr_score)/len(bpr_score)\n",
    "    else:\n",
    "        uid = userIDs[u]\n",
    "        ids, scores = model2.recommend(uid, Xui_csr[uid],N=nItems)\n",
    "        bs = scores[list(ids).index(itemIDs[g])]\n",
    "        \n",
    "    if(u not in userIDs):\n",
    "        lmf=0#sum(lmf_score)/len(lmf_score)\n",
    "    else:\n",
    "        uid = userIDs[u]\n",
    "        ids, scores = model3.recommend(uid, Xui_csr[uid],N=nItems)\n",
    "        lmf = scores[list(ids).index(itemIDs[g])]\n",
    "        \n",
    "    # Logic...\n",
    "    if g in mpg:\n",
    "        a=1\n",
    "    else:\n",
    "        a=0\n",
    "    predV = model1.predict([[1,max_sim,gamePop[g],bs,lmf]])[0]\n",
    "    #,gamePop[g],bs,lmf\n",
    "\n",
    "    #model.coef_[0][0]+model.coef_[0][1]*a+model.coef_[0][2]*max_sim #>0 ? 1:0\n",
    "    #print(predV)\n",
    "\n",
    "    #print(pred)\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(predV) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb4303",
   "metadata": {},
   "source": [
    "# Hours Played"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac71bfaf",
   "metadata": {},
   "source": [
    "### Implementation from HW3 - No regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37a297bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(path):\n",
    "    #f = gzip.open(path, 'rt')\n",
    "    f = open(path)\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        h = d['hours_transformed']\n",
    "        yield u,g,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df55c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "allHours = []\n",
    "for l in readJSON(\"train.json\"):\n",
    "    allHours.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95a31542",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(allHours)\n",
    "hoursTrain = allHours[:165000]\n",
    "hoursValid = allHours[165000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "177fd723",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHours = [r[2] for r in hoursTrain]\n",
    "globalAverage = sum(trainHours) * 1 / len(trainHours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd52c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoursPerItem = defaultdict(list)\n",
    "hoursPerUser = defaultdict(list)\n",
    "for user,game,info in hoursTrain:\n",
    "    hoursPerItem[game].append(info)\n",
    "    hoursPerUser[user].append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35075f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerGame = defaultdict(list)\n",
    "gamesPerUser = defaultdict(list)\n",
    "for user,game,info in hoursTrain:\n",
    "    usersPerGame[game].append(user)\n",
    "    gamesPerUser[user].append(game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53cd0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(lamb,iter):\n",
    "    betaU = {}\n",
    "    betaI = {}\n",
    "    for u in hoursPerUser:\n",
    "        betaU[u] = 0\n",
    "\n",
    "    for g in hoursPerItem:\n",
    "        betaI[g] = 0\n",
    "    \n",
    "    alpha = globalAverage \n",
    "    Ntrain = len(hoursTrain)\n",
    "\n",
    "    for i in range(iter):\n",
    "        tempAlpha = 0\n",
    "        for user,game,info in hoursTrain:\n",
    "            tempAlpha += info - betaU[user] - betaI[game]\n",
    "        tempAlpha = tempAlpha/Ntrain\n",
    "        \n",
    "        alpha = tempAlpha\n",
    "        #print(alpha)\n",
    "        \n",
    "        for u in hoursPerUser:\n",
    "            sizeIu = len(gamesPerUser[u])\n",
    "            tempbetaU = sum(hoursPerUser[u]) - sizeIu*alpha\n",
    "            for  g in gamesPerUser[u]:\n",
    "                tempbetaU -= betaI[g]\n",
    "            tempbetaU = tempbetaU/(sizeIu+lamb)\n",
    "            betaU[u] = tempbetaU\n",
    "        \n",
    "        for g in hoursPerItem:\n",
    "            sizeIg = len(usersPerGame[g])\n",
    "            tempbetaI = sum(hoursPerItem[g]) - sizeIg*alpha\n",
    "            for  u in usersPerGame[g]:\n",
    "                tempbetaI -= betaU[u]\n",
    "            tempbetaI = tempbetaI/(sizeIg+lamb)\n",
    "            betaI[g] = tempbetaI\n",
    "            \n",
    "        if((i+1)%10==0):\n",
    "            print(\"Iteration: \" + str(i+1))\n",
    "            print(\"Alpha: \" + str(alpha))\n",
    "            preds = []\n",
    "            for u,g,_ in hoursValid:\n",
    "                preds.append(alpha+betaU[u]+betaI[g])\n",
    "            y = [r[2] for r in hoursValid]\n",
    "            validMSE = numpy.mean(numpy.square(numpy.array(y) - numpy.array(preds)))\n",
    "            print(\"MSE: \"+ str(validMSE))\n",
    "            print(\"******************************\")\n",
    "        \n",
    "    return alpha,betaU,betaI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e20cc5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "Alpha: 3.4569930412531455\n",
      "MSE: 3.061680547939428\n",
      "******************************\n",
      "Iteration: 20\n",
      "Alpha: 3.294122093450818\n",
      "MSE: 3.059591560764978\n",
      "******************************\n",
      "Iteration: 30\n",
      "Alpha: 3.2093851667267566\n",
      "MSE: 3.0586832055684043\n",
      "******************************\n",
      "Iteration: 40\n",
      "Alpha: 3.1654082326684656\n",
      "MSE: 3.0582610592691992\n",
      "******************************\n",
      "Iteration: 50\n",
      "Alpha: 3.142603580029856\n",
      "MSE: 3.0580555448862405\n",
      "******************************\n",
      "Iteration: 60\n",
      "Alpha: 3.130781183415017\n",
      "MSE: 3.0579526207798597\n",
      "******************************\n",
      "Iteration: 70\n",
      "Alpha: 3.124652753490682\n",
      "MSE: 3.057900242717601\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "alpha,betaU,betaI = iterate(5,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf1d8db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    # Logic...\n",
    "    pred = alpha+betaU[u]+betaI[g]\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32304e",
   "metadata": {},
   "source": [
    "### Scipy optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2c10e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON2(path):\n",
    "    f = open(path)\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        h = d['hours_transformed']\n",
    "        yield u,g,h\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "42a121a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "allHours = []\n",
    "for l in readJSON2(\"train.json\"):\n",
    "    allHours.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c671ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainValidSplit(datals):\n",
    "\n",
    "    random.shuffle(datals)\n",
    "    data = pd.DataFrame(datals,columns = ['userID','gameID','hours'])\n",
    "    train, valid = data[:165000], data[165000:]\n",
    "\n",
    "    return data, train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6728d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]\n",
    "\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))\n",
    "    \n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d['userID'], d['gameID']) for index, d in train.iterrows()]\n",
    "    cost = MSE(predictions, labels)\n",
    "    #print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    print(\"Cost = \" + str(cost))\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(train)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for index, d in train.iterrows():\n",
    "        u,i = d['userID'], d['gameID']\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d['hours']\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "77c66f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost = 5.290959200480984\n",
      "Cost = 5.172056515137862\n",
      "Cost = 4.763495442850006\n",
      "Cost = 15.545584592513642\n",
      "Cost = 4.570176495541972\n",
      "Cost = 4.087647232371297\n",
      "Cost = 4.074834646145797\n",
      "Cost = 4.02536025443987\n",
      "Cost = 3.8558779387483657\n",
      "Cost = 3.531735949981736\n",
      "Cost = 3.3591163189760156\n",
      "Cost = 3.1752274370865297\n",
      "Cost = 3.1031109236446763\n",
      "Cost = 3.0254233089299363\n",
      "Cost = 2.982780278250415\n",
      "Cost = 2.9529674236876136\n",
      "Cost = 2.9418800135168857\n",
      "Cost = 2.9327184300120455\n",
      "Cost = 4.81646866755446\n",
      "Cost = 2.932671094720736\n",
      "Cost = 2.929367391021621\n",
      "Cost = 2.926363354501926\n",
      "Cost = 2.924094753579522\n",
      "Cost = 2.922192751511797\n",
      "Cost = 2.920115710730171\n",
      "Cost = 2.9181272200855153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.11811897,  0.34117967,  0.7521703 , ...,  0.42361739,\n",
       "        -0.17546085,  3.25501628]),\n",
       " 2.9181272200855153,\n",
       " {'grad': array([-6.97385435e-04, -2.27187960e-06, -2.90026926e-05, ...,\n",
       "          2.45444423e-06, -9.71493554e-07, -1.87175843e-05]),\n",
       "  'task': 'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT',\n",
       "  'funcalls': 26,\n",
       "  'nit': 20,\n",
       "  'warnflag': 1})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb = 0.0000275\n",
    "data, train, valid = trainValidSplit(allHours)\n",
    "\n",
    "ratingMean = train['hours'].mean()\n",
    "alpha = ratingMean\n",
    "\n",
    "labels = train['hours']\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "\n",
    "users = list(set(train['userID']))\n",
    "items = list(set(train['gameID']))\n",
    "nUsers = len(users)\n",
    "nItems = len(items)\n",
    "#fmin_l_bfgs_b\n",
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0]*(nUsers+nItems),\n",
    "                             derivative, args = (labels, lamb),maxiter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1d2b5e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 2.869\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for index, d in valid.iterrows():\n",
    "    u, i = d['userID'], d['gameID']\n",
    "    if u in userBiases and i in itemBiases:\n",
    "        predictions.append(prediction(u, i))\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "\n",
    "print(\"MSE %.3f\" % MSE(predictions, valid['hours']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "64180315",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    if u in userBiases and g in itemBiases:\n",
    "        pred = prediction(u, g)\n",
    "    else:\n",
    "        pred = 0\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb72bf",
   "metadata": {},
   "source": [
    "### Tensorflow LFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d01f0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "interactions = []\n",
    "f = open(\"train.json\")\n",
    "f.readline()\n",
    "\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    i = d['gameID']\n",
    "    r = d['hours_transformed']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "\n",
    "    interactions.append((u,i,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a0d54dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174999"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(interactions)\n",
    "len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d31f0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = int(len(interactions) * 0.9)\n",
    "nTest = len(interactions) - nTrain\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsTest = interactions[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8ab47af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "for u,i,r in interactionsTrain:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3f164a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = sum([r for _,_,r in interactionsTrain]) / len(interactionsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "182bbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8553e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModelBiasOnly(tf.keras.Model):\n",
    "    def __init__(self, mu, lamb):\n",
    "        super(LatentFactorModelBiasOnly, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i]\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "09f3c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStepBiasOnly(model, interactionsTrain):\n",
    "    Nsamples = 20000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactionsTrain)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "        (grad, var) in zip(gradients, model.trainable_variables)\n",
    "        if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2a81f8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 1.903913\n",
      "3.72244084054001\n",
      "iteration 20, objective = 1.6490375\n",
      "3.2941192996675004\n",
      "iteration 30, objective = 1.5630397\n",
      "3.1529835833335356\n",
      "iteration 40, objective = 1.5568713\n",
      "3.0905484621327126\n",
      "iteration 50, objective = 1.5434971\n",
      "3.066342441437411\n",
      "iteration 60, objective = 1.5824833\n",
      "3.058982698534239\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(0.1)\n",
    "modelBiasOnly = LatentFactorModelBiasOnly(mu, 0.000025)\n",
    "for i in range(60):\n",
    "    obj = trainingStepBiasOnly(modelBiasOnly, interactionsTrain)\n",
    "    if (i % 10 == 9): \n",
    "        print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))\n",
    "    if (i % 10 == 9):    \n",
    "        biasOnlyPredictions =[modelBiasOnly.predict(userIDs[u],itemIDs[i]).numpy() for u,i,_ in interactionsTest]\n",
    "        labels = [r for _,_,r in interactionsTest]\n",
    "        \n",
    "        print(MSE(biasOnlyPredictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b04b1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "     \n",
    "    if u in userIDs and g in itemIDs:\n",
    "        pred = modelBiasOnly.predict(userIDs[u],itemIDs[g]).numpy()\n",
    "    else:\n",
    "        pred = mu\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9911e6b",
   "metadata": {},
   "source": [
    "### Light FM with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "beeb936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readJSON(path):\n",
    "    #f = gzip.open(path, 'rt')\n",
    "    f = open(path)\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        h = d['hours_transformed']\n",
    "        yield u,g,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84cf9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "gameIDs = {}\n",
    "\n",
    "f = open(\"train.json\")\n",
    "f.readline()\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    g = d['gameID']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not g in gameIDs: gameIDs[g] = len(gameIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "51b98869",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = []\n",
    "for l in readJSON(\"train.json\"):\n",
    "    rawData.append(l)\n",
    "random.shuffle(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "92f773fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerGame = defaultdict(set)\n",
    "gamesPerUser = defaultdict(set)\n",
    "for user,game,_ in rawData:\n",
    "    usersPerGame[game].add(user)\n",
    "    gamesPerUser[user].add(game)\n",
    "games = list(usersPerGame.keys())\n",
    "users = list(gamesPerUser.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fdac624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = int(len(rawData) * 0.95)\n",
    "nTest = len(rawData) - nTrain\n",
    "train = rawData[:nTrain]\n",
    "test = rawData[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e16a457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train, columns=[\"user\", \"item\", \"interaction\"])\n",
    "df_train[\"user_id\"] = df_train[\"user\"].map(userIDs)\n",
    "df_train[\"item_id\"] = df_train[\"item\"].map(gameIDs)\n",
    "df_train = df_train[[\"user_id\", \"item_id\", \"interaction\"]]\n",
    "n_users = df_train['user_id'].nunique()\n",
    "n_items = df_train['item_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c7d2bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ncf(\n",
    "    number_of_users: int,\n",
    "    number_of_items: int,\n",
    "    latent_dim_mf: int = 2,\n",
    "    latent_dim_mlp: int = 2,\n",
    "    reg_mf: int = 0.001,\n",
    "    reg_mlp: int = 0.002,\n",
    "    dense_layers: List[int] = [16, 8],\n",
    "    reg_layers: List[int] = [0.01, 0.01],\n",
    ") -> keras.Model:\n",
    "\n",
    "    # input layer\n",
    "    user = Input(shape=(), dtype=\"int32\", name=\"user_id\")\n",
    "    item = Input(shape=(), dtype=\"int32\", name=\"item_id\")\n",
    "\n",
    "    # embedding layers\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mf_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mlp_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    # MF vector\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user))\n",
    "    mf_item_latent = Flatten()(mf_item_embedding(item))\n",
    "    mf_cat_latent = Multiply()([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP vector\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user))\n",
    "    mlp_item_latent = Flatten()(mlp_item_embedding(item))\n",
    "    mlp_cat_latent = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    mlp_vector = mlp_cat_latent\n",
    "\n",
    "    # build dense layers for model\n",
    "    for i in range(len(dense_layers)):\n",
    "        layer = Dense(\n",
    "            dense_layers[i],\n",
    "            activity_regularizer=l2(reg_layers[i]),\n",
    "            name=\"layer%d\" % i,\n",
    "        )\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    predict_layer = Concatenate()([mf_cat_latent, mlp_vector])\n",
    "\n",
    "    result = Dense(\n",
    "        1, name=\"interaction\"\n",
    "    )\n",
    "\n",
    "    output = result(predict_layer)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[user, item],\n",
    "        outputs=[output],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5b58f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(df: pd.DataFrame,targets: List[str],val_split: float = 0.05,batch_size: int = 4096,seed=None,):\n",
    "\n",
    "    n_val = round(df.shape[0] * val_split)\n",
    "    if seed:\n",
    "        # shuffle all the rows\n",
    "        x = df.sample(frac=1, random_state=seed).to_dict(\"series\")\n",
    "    else:\n",
    "        x = df.to_dict(\"series\")\n",
    "    y = dict()\n",
    "    for t in targets:\n",
    "        y[t] = x.pop(t)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "    ds_val = ds.take(n_val).batch(batch_size)\n",
    "    ds_train = ds.skip(n_val).batch(batch_size)\n",
    "    \n",
    "    return ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "05e86da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "ncf_model = create_ncf(n_users, n_items)\n",
    "\n",
    "ncf_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    #loss=\"binary_crossentropy\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "            tf.keras.metrics.RootMeanSquaredError(name='root_mean_squared_error')\n",
    "    ],\n",
    ")\n",
    "ncf_model._name = \"neural_collaborative_filtering\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "77617fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "39/39 [==============================] - 1s 7ms/step - loss: 17.7503 - root_mean_squared_error: 4.2014 - val_loss: 16.0379 - val_root_mean_squared_error: 3.9950\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 13.0083 - root_mean_squared_error: 3.5936 - val_loss: 9.8855 - val_root_mean_squared_error: 3.1234\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 7.0535 - root_mean_squared_error: 2.6216 - val_loss: 5.2788 - val_root_mean_squared_error: 2.2468\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 4.6611 - root_mean_squared_error: 2.1013 - val_loss: 4.4039 - val_root_mean_squared_error: 2.0387\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.9965 - root_mean_squared_error: 1.9365 - val_loss: 3.8818 - val_root_mean_squared_error: 1.9063\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 3.5513 - root_mean_squared_error: 1.8167 - val_loss: 3.5516 - val_root_mean_squared_error: 1.8162\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.3025 - root_mean_squared_error: 1.7460 - val_loss: 3.3869 - val_root_mean_squared_error: 1.7701\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.1823 - root_mean_squared_error: 1.7116 - val_loss: 3.3083 - val_root_mean_squared_error: 1.7486\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.1203 - root_mean_squared_error: 1.6947 - val_loss: 3.2668 - val_root_mean_squared_error: 1.7382\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 3.0837 - root_mean_squared_error: 1.6854 - val_loss: 3.2424 - val_root_mean_squared_error: 1.7328\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 3.0595 - root_mean_squared_error: 1.6800 - val_loss: 3.2267 - val_root_mean_squared_error: 1.7299\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0421 - root_mean_squared_error: 1.6765 - val_loss: 3.2157 - val_root_mean_squared_error: 1.7285\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0287 - root_mean_squared_error: 1.6743 - val_loss: 3.2074 - val_root_mean_squared_error: 1.7277\n",
      "Epoch 14/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0179 - root_mean_squared_error: 1.6729 - val_loss: 3.2005 - val_root_mean_squared_error: 1.7274\n",
      "Epoch 15/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0087 - root_mean_squared_error: 1.6718 - val_loss: 3.1945 - val_root_mean_squared_error: 1.7274\n",
      "Epoch 16/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0007 - root_mean_squared_error: 1.6712 - val_loss: 3.1891 - val_root_mean_squared_error: 1.7274\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_val = make_tf_dataset(df_train, [\"interaction\"])\n",
    "N_EPOCHS = 30\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_root_mean_squared_error\", patience=1\n",
    ")\n",
    "\n",
    "train_hist = ncf_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8581361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame(test, columns=[\"user\", \"item\", \"interaction\"])\n",
    "df_test[\"user_id\"] = df_test[\"user\"].map(userIDs)\n",
    "df_test[\"item_id\"] = df_test[\"item\"].map(gameIDs)\n",
    "df_test=df_test[[\"user_id\", \"item_id\", \"interaction\"]]\n",
    "ds_test, _ = make_tf_dataset(df_test, [\"interaction\"], val_split=0, seed=None)\n",
    "ncf_predictions = ncf_model.predict(ds_test)\n",
    "df_test[\"ncf_predictions\"] = ncf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "21704678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0314861250886445"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(np.array(df_test['interaction']) - np.array(df_test['ncf_predictions'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827212bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "15178c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "dfc = pd.read_csv(\"pairs_Hours.csv\")\n",
    "dfc[\"user_id\"] = dfc[\"userID\"].map(userIDs)\n",
    "dfc[\"item_id\"] = dfc[\"gameID\"].map(gameIDs)\n",
    "dfc[\"interaction\"] = dfc[\"prediction\"]\n",
    "dfc=dfc[[\"user_id\", \"item_id\", \"interaction\"]]\n",
    "dsc, _ = make_tf_dataset(dfc, [\"interaction\"], val_split=0, seed=None)\n",
    "preds = ncf_model.predict(dsc)\n",
    "dfc[\"ncf_predictions\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a19d9410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>ncf_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1374</td>\n",
       "      <td>459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.272638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5565</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>759</td>\n",
       "      <td>281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.285567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928</td>\n",
       "      <td>784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.951291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6216</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.294409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4630</td>\n",
       "      <td>392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.995924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5520</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.865772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2930</td>\n",
       "      <td>1889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.213949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>892</td>\n",
       "      <td>1728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.620036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1111</td>\n",
       "      <td>242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.395475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  interaction  ncf_predictions\n",
       "0        1374      459          NaN         4.272638\n",
       "1        5565      590          NaN         0.990524\n",
       "2         759      281          NaN         5.285567\n",
       "3        1928      784          NaN         2.951291\n",
       "4        6216      600          NaN         3.294409\n",
       "...       ...      ...          ...              ...\n",
       "9995     4630      392          NaN         6.995924\n",
       "9996     5520      481          NaN         3.865772\n",
       "9997     2930     1889          NaN         3.213949\n",
       "9998      892     1728          NaN         3.620036\n",
       "9999     1111      242          NaN         6.395475\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b22c6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dfc.values.tolist()\n",
    "i=0\n",
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    pred = sample[i][3]\n",
    "    #print(sample[i])\n",
    "    i = i+1\n",
    "    \n",
    "    #print(pred)\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a5c660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
