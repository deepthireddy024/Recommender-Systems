{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c2c70a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import lightfm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from lightfm import LightFM\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from typing import List\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1064dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readJSON(path):\n",
    "    #f = gzip.open(path, 'rt')\n",
    "    f = open(path)\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        d = eval(l)\n",
    "        u = d['userID']\n",
    "        g = d['gameID']\n",
    "        h = d['hours_transformed']\n",
    "        yield u,g,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8ced9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "gameIDs = {}\n",
    "\n",
    "f = open(\"train.json\")\n",
    "f.readline()\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    g = d['gameID']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not g in gameIDs: gameIDs[g] = len(gameIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "id": "3037778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = []\n",
    "for l in readJSON(\"train.json\"):\n",
    "    rawData.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "id": "7f5500b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rawData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "id": "c560ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerGame = defaultdict(set)\n",
    "gamesPerUser = defaultdict(set)\n",
    "for user,game,_ in rawData:\n",
    "    usersPerGame[game].add(user)\n",
    "    gamesPerUser[user].add(game)\n",
    "games = list(usersPerGame.keys())\n",
    "users = list(gamesPerUser.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "id": "852ccf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = int(len(rawData) * 0.95)\n",
    "nTest = len(rawData) - nTrain\n",
    "train = rawData[:nTrain]\n",
    "test = rawData[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "id": "e9ad1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train, columns=[\"user\", \"item\", \"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "id": "e02e0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"user_id\"] = df_train[\"user\"].map(userIDs)\n",
    "df_train[\"item_id\"] = df_train[\"item\"].map(gameIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "id": "c2b9d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[[\"user_id\", \"item_id\", \"interaction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "id": "2be79226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ncf(\n",
    "    number_of_users: int,\n",
    "    number_of_items: int,\n",
    "    latent_dim_mf: int = 2,\n",
    "    latent_dim_mlp: int = 2,\n",
    "    reg_mf: int = 0.001,\n",
    "    reg_mlp: int = 0.002,\n",
    "    dense_layers: List[int] = [16, 8],\n",
    "    reg_layers: List[int] = [0.01, 0.01],\n",
    "#     activation_dense: str = \"relu\",\n",
    ") -> keras.Model:\n",
    "\n",
    "    # input layer\n",
    "    user = Input(shape=(), dtype=\"int32\", name=\"user_id\")\n",
    "    item = Input(shape=(), dtype=\"int32\", name=\"item_id\")\n",
    "\n",
    "    # embedding layers\n",
    "    mf_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mf_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mf,\n",
    "        name=\"mf_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mf),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    mlp_user_embedding = Embedding(\n",
    "        input_dim=number_of_users,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_user_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "    mlp_item_embedding = Embedding(\n",
    "        input_dim=number_of_items,\n",
    "        output_dim=latent_dim_mlp,\n",
    "        name=\"mlp_item_embedding\",\n",
    "        embeddings_initializer=\"RandomNormal\",\n",
    "        embeddings_regularizer=l2(reg_mlp),\n",
    "        input_length=1,\n",
    "    )\n",
    "\n",
    "    # MF vector\n",
    "    mf_user_latent = Flatten()(mf_user_embedding(user))\n",
    "    mf_item_latent = Flatten()(mf_item_embedding(item))\n",
    "    mf_cat_latent = Multiply()([mf_user_latent, mf_item_latent])\n",
    "\n",
    "    # MLP vector\n",
    "    mlp_user_latent = Flatten()(mlp_user_embedding(user))\n",
    "    mlp_item_latent = Flatten()(mlp_item_embedding(item))\n",
    "    mlp_cat_latent = Concatenate()([mlp_user_latent, mlp_item_latent])\n",
    "\n",
    "    mlp_vector = mlp_cat_latent\n",
    "\n",
    "    # build dense layers for model\n",
    "    for i in range(len(dense_layers)):\n",
    "        layer = Dense(\n",
    "            dense_layers[i],\n",
    "            activity_regularizer=l2(reg_layers[i]),\n",
    "            name=\"layer%d\" % i,\n",
    "        )\n",
    "        mlp_vector = layer(mlp_vector)\n",
    "\n",
    "    predict_layer = Concatenate()([mf_cat_latent, mlp_vector])\n",
    "\n",
    "    result = Dense(\n",
    "        1, name=\"interaction\"\n",
    "    )\n",
    "\n",
    "    output = result(predict_layer)\n",
    "\n",
    "    model = Model(\n",
    "        inputs=[user, item],\n",
    "        outputs=[output],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "id": "84180def",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "n_users = df_train['user_id'].nunique()\n",
    "n_items = df_train['item_id'].nunique()\n",
    "ncf_model = create_ncf(n_users, n_items)\n",
    "\n",
    "ncf_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    #loss=\"binary_crossentropy\",\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\n",
    "            tf.keras.metrics.RootMeanSquaredError(name='root_mean_squared_error')\n",
    "    ],\n",
    ")\n",
    "ncf_model._name = \"neural_collaborative_filtering\"\n",
    "#ncf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "id": "86be73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(\n",
    "    df: pd.DataFrame,\n",
    "    targets: List[str],\n",
    "    val_split: float = 0.05,\n",
    "    batch_size: int = 4096,\n",
    "    seed=None,\n",
    "):\n",
    "\n",
    "    n_val = round(df.shape[0] * val_split)\n",
    "    if seed:\n",
    "        # shuffle all the rows\n",
    "        x = df.sample(frac=1, random_state=seed).to_dict(\"series\")\n",
    "    else:\n",
    "        x = df.to_dict(\"series\")\n",
    "    y = dict()\n",
    "    for t in targets:\n",
    "        y[t] = x.pop(t)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "    ds_val = ds.take(n_val).batch(batch_size)\n",
    "    ds_train = ds.skip(n_val).batch(batch_size)\n",
    "    return ds_train, ds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "id": "8c5411f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_val = make_tf_dataset(df_train, [\"interaction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "id": "93a3c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "39/39 [==============================] - 1s 8ms/step - loss: 17.6146 - root_mean_squared_error: 4.1844 - val_loss: 15.5336 - val_root_mean_squared_error: 3.9298\n",
      "Epoch 2/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 12.5769 - root_mean_squared_error: 3.5315 - val_loss: 9.2803 - val_root_mean_squared_error: 3.0239\n",
      "Epoch 3/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 6.6771 - root_mean_squared_error: 2.5493 - val_loss: 5.0584 - val_root_mean_squared_error: 2.2004\n",
      "Epoch 4/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 4.4918 - root_mean_squared_error: 2.0655 - val_loss: 4.2636 - val_root_mean_squared_error: 2.0097\n",
      "Epoch 5/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.8518 - root_mean_squared_error: 1.9045 - val_loss: 3.7719 - val_root_mean_squared_error: 1.8830\n",
      "Epoch 6/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.4469 - root_mean_squared_error: 1.7937 - val_loss: 3.4986 - val_root_mean_squared_error: 1.8076\n",
      "Epoch 7/30\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 3.2410 - root_mean_squared_error: 1.7344 - val_loss: 3.3787 - val_root_mean_squared_error: 1.7738\n",
      "Epoch 8/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.1447 - root_mean_squared_error: 1.7066 - val_loss: 3.3247 - val_root_mean_squared_error: 1.7592\n",
      "Epoch 9/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0930 - root_mean_squared_error: 1.6924 - val_loss: 3.2972 - val_root_mean_squared_error: 1.7525\n",
      "Epoch 10/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0608 - root_mean_squared_error: 1.6841 - val_loss: 3.2819 - val_root_mean_squared_error: 1.7494\n",
      "Epoch 11/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0387 - root_mean_squared_error: 1.6789 - val_loss: 3.2727 - val_root_mean_squared_error: 1.7481\n",
      "Epoch 12/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0224 - root_mean_squared_error: 1.6755 - val_loss: 3.2665 - val_root_mean_squared_error: 1.7478\n",
      "Epoch 13/30\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 3.0098 - root_mean_squared_error: 1.6733 - val_loss: 3.2617 - val_root_mean_squared_error: 1.7479\n"
     ]
    }
   ],
   "source": [
    "\n",
    "N_EPOCHS = 30\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_root_mean_squared_error\", patience=1\n",
    ")\n",
    "\n",
    "train_hist = ncf_model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=[tensorboard_callback, early_stopping_callback],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "id": "8a11a767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame(test, columns=[\"user\", \"item\", \"interaction\"])\n",
    "df_test[\"user_id\"] = df_test[\"user\"].map(userIDs)\n",
    "df_test[\"item_id\"] = df_test[\"item\"].map(gameIDs)\n",
    "df_test=df_test[[\"user_id\", \"item_id\", \"interaction\"]]\n",
    "ds_test, _ = make_tf_dataset(df_test, [\"interaction\"], val_split=0, seed=None)\n",
    "ncf_predictions = ncf_model.predict(ds_test)\n",
    "df_test[\"ncf_predictions\"] = ncf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "id": "889dfbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>ncf_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5697</td>\n",
       "      <td>968</td>\n",
       "      <td>2.867896</td>\n",
       "      <td>1.753195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3395</td>\n",
       "      <td>415</td>\n",
       "      <td>3.655352</td>\n",
       "      <td>6.697020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2364</td>\n",
       "      <td>1033</td>\n",
       "      <td>1.137504</td>\n",
       "      <td>5.564166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>1533</td>\n",
       "      <td>3.321928</td>\n",
       "      <td>3.046285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3686</td>\n",
       "      <td>1317</td>\n",
       "      <td>2.432959</td>\n",
       "      <td>3.790053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745</th>\n",
       "      <td>1388</td>\n",
       "      <td>645</td>\n",
       "      <td>2.405992</td>\n",
       "      <td>2.356273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8746</th>\n",
       "      <td>94</td>\n",
       "      <td>1245</td>\n",
       "      <td>3.277985</td>\n",
       "      <td>4.075471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8747</th>\n",
       "      <td>1297</td>\n",
       "      <td>152</td>\n",
       "      <td>1.321928</td>\n",
       "      <td>1.648593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8748</th>\n",
       "      <td>6032</td>\n",
       "      <td>1419</td>\n",
       "      <td>4.781360</td>\n",
       "      <td>5.744066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8749</th>\n",
       "      <td>5574</td>\n",
       "      <td>1227</td>\n",
       "      <td>4.626439</td>\n",
       "      <td>3.514979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  interaction  ncf_predictions\n",
       "0        5697      968     2.867896         1.753195\n",
       "1        3395      415     3.655352         6.697020\n",
       "2        2364     1033     1.137504         5.564166\n",
       "3          88     1533     3.321928         3.046285\n",
       "4        3686     1317     2.432959         3.790053\n",
       "...       ...      ...          ...              ...\n",
       "8745     1388      645     2.405992         2.356273\n",
       "8746       94     1245     3.277985         4.075471\n",
       "8747     1297      152     1.321928         1.648593\n",
       "8748     6032     1419     4.781360         5.744066\n",
       "8749     5574     1227     4.626439         3.514979\n",
       "\n",
       "[8750 rows x 4 columns]"
      ]
     },
     "execution_count": 1335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "id": "0843f111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.019717403456202"
      ]
     },
     "execution_count": 1336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(np.array(df_test['interaction']) - np.array(df_test['ncf_predictions'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "id": "a1849082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "dfc = pd.read_csv(\"pairs_Hours.csv\")\n",
    "dfc[\"user_id\"] = dfc[\"userID\"].map(userIDs)\n",
    "dfc[\"item_id\"] = dfc[\"gameID\"].map(gameIDs)\n",
    "dfc[\"interaction\"] = dfc[\"prediction\"]\n",
    "dfc=dfc[[\"user_id\", \"item_id\", \"interaction\"]]\n",
    "dsc, _ = make_tf_dataset(dfc, [\"interaction\"], val_split=0, seed=None)\n",
    "preds = ncf_model.predict(dsc)\n",
    "dfc[\"ncf_predictions\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "id": "c851664b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>ncf_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1374</td>\n",
       "      <td>459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.074759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5565</td>\n",
       "      <td>590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.117396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>759</td>\n",
       "      <td>281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.171386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1928</td>\n",
       "      <td>784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.958941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6216</td>\n",
       "      <td>600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.097157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4630</td>\n",
       "      <td>392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.688177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>5520</td>\n",
       "      <td>481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.045860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2930</td>\n",
       "      <td>1889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.361379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>892</td>\n",
       "      <td>1728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.649117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1111</td>\n",
       "      <td>242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.279250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id  interaction  ncf_predictions\n",
       "0        1374      459          NaN         4.074759\n",
       "1        5565      590          NaN         1.117396\n",
       "2         759      281          NaN         5.171386\n",
       "3        1928      784          NaN         2.958941\n",
       "4        6216      600          NaN         3.097157\n",
       "...       ...      ...          ...              ...\n",
       "9995     4630      392          NaN         6.688177\n",
       "9996     5520      481          NaN         4.045860\n",
       "9997     2930     1889          NaN         3.361379\n",
       "9998      892     1728          NaN         3.649117\n",
       "9999     1111      242          NaN         6.279250\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 1326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "id": "1b55aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dfc.values.tolist()\n",
    "#sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "id": "7965ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "    \n",
    "    pred = sample[i][3]\n",
    "    #print(sample[i])\n",
    "    i = i+1\n",
    "    \n",
    "    #print(pred)\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
