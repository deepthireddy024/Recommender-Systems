{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afbeb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52b929c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "interactions = []\n",
    "f = open(\"train.json\")\n",
    "f.readline()\n",
    "#for d in parse(dataDir + \"goodreads_reviews_comics_graphic.json.gz\"):\n",
    "for l in f:\n",
    "    d = eval(l)\n",
    "    u = d['userID']\n",
    "    i = d['gameID']\n",
    "    r = d['hours_transformed']\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "\n",
    "    interactions.append((u,i,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f81fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e59f4cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174999"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(interactions)\n",
    "len(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7c61d46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = int(len(interactions) * 0.9)\n",
    "nTest = len(interactions) - nTrain\n",
    "interactionsTrain = interactions[:nTrain]\n",
    "interactionsTest = interactions[nTrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7eff0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactionsTrain = [i for i in interactionsTrain if i[2]<11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "33c5e085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157499"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interactionsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8ad83bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "for u,i,r in interactionsTrain:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "30986c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = sum([r for _,_,r in interactionsTrain]) / len(interactionsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63107b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "772d352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentFactorModelBiasOnly(tf.keras.Model):\n",
    "    def __init__(self, mu, lamb):\n",
    "        super(LatentFactorModelBiasOnly, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = self.alpha + self.betaU[u] + self.betaI[i]\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2) +\\\n",
    "                            tf.reduce_sum(self.betaI**2))\n",
    "    \n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i\n",
    "        return pred\n",
    "    \n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0c2c464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStepBiasOnly(model, interactionsTrain):\n",
    "    Nsamples = 100000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactionsTrain)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "        (grad, var) in zip(gradients, model.trainable_variables)\n",
    "        if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31bfc044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10, objective = 1.8315191\n",
      "3.649967212786028\n",
      "iteration 20, objective = 1.6335082\n",
      "iteration 30, objective = 1.5461633\n",
      "3.1031634056994033\n",
      "iteration 40, objective = 1.5339885\n",
      "iteration 50, objective = 1.5177698\n",
      "3.0522965390434167\n",
      "iteration 60, objective = 1.517798\n",
      "iteration 70, objective = 1.5172275\n",
      "3.0494469699587246\n",
      "iteration 80, objective = 1.5209827\n",
      "iteration 90, objective = 1.5211657\n",
      "3.050670965092708\n",
      "iteration 100, objective = 1.5221378\n",
      "iteration 110, objective = 1.5219678\n",
      "3.047038857103788\n",
      "iteration 120, objective = 1.5268795\n",
      "iteration 130, objective = 1.5115079\n",
      "3.0431120107061567\n",
      "iteration 140, objective = 1.5128993\n",
      "iteration 150, objective = 1.5036949\n",
      "3.0454241461396294\n",
      "iteration 160, objective = 1.5091177\n",
      "iteration 170, objective = 1.5108358\n",
      "3.044040568716573\n",
      "iteration 180, objective = 1.5086373\n",
      "iteration 190, objective = 1.5102401\n",
      "3.0492721725185836\n",
      "iteration 200, objective = 1.5199573\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(0.1)\n",
    "modelBiasOnly = LatentFactorModelBiasOnly(mu, 0.000025)\n",
    "for i in range(200):\n",
    "    obj = trainingStepBiasOnly(modelBiasOnly, interactionsTrain)\n",
    "    if (i % 10 == 9): \n",
    "        print(\"iteration \" + str(i+1) + \", objective = \" + str(obj))\n",
    "    if (i % 20 == 9):    \n",
    "        biasOnlyPredictions =[modelBiasOnly.predict(userIDs[u],itemIDs[i]).numpy() for u,i,_ in interactionsTest]\n",
    "        labels = [r for _,_,r in interactionsTest]\n",
    "        \n",
    "        print(MSE(biasOnlyPredictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265fb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Hours.csv\", 'w')\n",
    "for l in open(\"pairs_Hours.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,g = l.strip().split(',')\n",
    "     \n",
    "    if u in userIDs and g in itemIDs:\n",
    "        pred = modelBiasOnly.predict(userIDs[u],itemIDs[g]).numpy()\n",
    "    else:\n",
    "        pred = mu\n",
    "    \n",
    "    _ = predictions.write(u + ',' + g + ',' + str(pred) + '\\n')\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6065e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
